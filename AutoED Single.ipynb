{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.core.numeric import NaN\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def autoencoder(dfx, y, dims, component):\n",
    "    '''\n",
    "    Autoencoder model\n",
    "    \n",
    "    @params:\n",
    "        dfx: DataFrame of normalized x values\n",
    "        y: Predicted value\n",
    "        dims: Number of dimensions\n",
    "        component: Name of gas or particulate\n",
    "    '''\n",
    "\n",
    "    regr = LinearRegression()\n",
    "    variance_list = []\n",
    "    r2_list = []\n",
    "    num_of_comp = list(range(2,dims+1))\n",
    "\n",
    "    for i in num_of_comp:\n",
    "        print('---------- Autoencoder dim {} for {} ----------'.format(i, component))\n",
    "        # Training and test splits\n",
    "        train, dev, train_labels, dev_labels = train_test_split(dfx, y, test_size=0.20, random_state=40)\n",
    "        train, test, train_labels, test_labels = train_test_split(train, train_labels, test_size=0.20, random_state=40)\n",
    "        input_data = Input(shape=(191,))\n",
    "\n",
    "        x_train = train.loc[:, train.columns]\n",
    "        x_test = test.loc[:, test.columns]\n",
    "        x_dev = dev.loc[:, dev.columns]\n",
    "\n",
    "        encoded = Dense(i, activation='LeakyReLU', name='bottleneck')(input_data)\n",
    "        decoded = Dense(191, activation='LeakyReLU')(encoded)\n",
    "\n",
    "        autoencoder = Model(input_data, decoded)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        autoencoder.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "        autoencoder.summary()\n",
    "\n",
    "        trained_model = autoencoder.fit(\n",
    "            x_train, \n",
    "            x_train, \n",
    "            batch_size=64, \n",
    "            epochs=150, \n",
    "            verbose=1,\n",
    "            validation_data=(x_dev, x_dev)\n",
    "        )\n",
    "\n",
    "        # Bottleneck representation\n",
    "        encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
    "        encoded_data = encoder.predict(x_train)  \n",
    "        decoded_output = autoencoder.predict(x_train)  \n",
    "        decoded_output_test = autoencoder.predict(x_test)\n",
    "\n",
    "        # Variance score explanation\n",
    "        regr.fit(encoded_data, train_labels)\n",
    "\n",
    "        encoded_data_test = encoder.predict(x_test)\n",
    "        y_pred = regr.predict(encoded_data_test) # << Pass x_test to get predicitons for original uncompressed\n",
    "        \n",
    "        # Variance and r2 scores for the regression model\n",
    "        variance = regr.score(encoded_data_test, test_labels) # << pass in x test for uncompressed values\n",
    "        r2_val = r2_score(test_labels, y_pred)\n",
    "        print ('Variance score: %.2f' % variance)\n",
    "        print ('R Square', r2_val)\n",
    "\n",
    "        # Add r2/variance to lists\n",
    "        variance_list.append(variance)\n",
    "        r2_list.append(r2_val)        \n",
    "\n",
    "    return (variance_list, r2_list, encoded_data)\n",
    "\n",
    "\n",
    "def ae_run(dims, component_names):\n",
    "    '''\n",
    "    Run and train the autoencoder model\n",
    "    \n",
    "    @params:\n",
    "        dims: Number of dimensions\n",
    "        component_names: Gas/particulate list\n",
    "    '''\n",
    "\n",
    "    for component in component_names:\n",
    "        print('---------- Beginning Autoencoder training for {} ----------'.format(component))\n",
    "        df = pd.read_csv('C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-testing\\\\Universal-Embeddings-Nick\\\\data\\\\{}_data_clean.csv'.format(component))\n",
    "        \n",
    "        # Features list and removal of city, lat, lon\n",
    "        features = list(df.columns.values)\n",
    "        del features[:3] \n",
    "        del features[-1]\n",
    "\n",
    "        # y value list using last day of 7-month data\n",
    "        y = df.loc[:, ['{}_2021_06_06'.format(component)]].values\n",
    "\n",
    "        # Normalize x values; save in data frame\n",
    "        x = df.loc[:, features].values\n",
    "        x = Normalizer().fit_transform(x)\n",
    "        dfx = pd.DataFrame(x)\n",
    "\n",
    "        # Train Autoencoder model\n",
    "        variance, r2, X_train = autoencoder(dfx, y, dims, component)\n",
    "\n",
    "        # Normalize var and r2 so they are same length as ax1 and ax2\n",
    "        append_size = len(X_train[:,0]) - dims + 1\n",
    "        norm = np.empty(append_size)\n",
    "        norm[:] = np.NaN\n",
    "        var_norm = [*variance, *norm]\n",
    "        r2_norm = [*r2, *norm]\n",
    "\n",
    "        # Output dict to write \n",
    "        output_dict = {\n",
    "            '{}_X_train_ax1'.format(component): X_train[:,0],\n",
    "            '{}_X_train_ax2'.format(component) : X_train[:,1],\n",
    "            '{}_var'.format(component) : var_norm,\n",
    "            '{}_r2'.format(component) : r2_norm\n",
    "        }\n",
    "\n",
    "        # Write entry to file\n",
    "        file_name = 'C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-testing\\\\Universal-Embeddings-Nick\\\\data\\\\{}_ae_results_grid_para.csv'.format(component)\n",
    "        write_data = pd.DataFrame(data=output_dict)\n",
    "        write_data.to_csv(path_or_buf=file_name, index=False)\n",
    "    \n",
    "### RUN ###\n",
    "\n",
    "#COMPONENT_NAMES = ['co', 'no', 'no2', 'o3', 'so2', 'pm2_5', 'pm10', 'nh3']\n",
    "COMPONENT_NAMES = ['pm10', 'nh3']\n",
    "#COMPONENT_NAMES = ['no']\n",
    "COLORS_LIST = ['tab:blue', 'tab:green', 'tab:orange', 'tab:red', 'tab:purple', 'tab:cyan', 'tab:olive', 'tab:pink']\n",
    "# Starting dimensions; Change this to edit\n",
    "DIMS = 191\n",
    "\n",
    "# Method tests\n",
    "ae_run(DIMS, COMPONENT_NAMES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# print(\"GPU's Available \", len(physical_devices))\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "import numpy as np\n",
    "from numpy.core.numeric import NaN\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "!python --version\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.core.numeric import NaN\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def autoencoder(dfx, y, dims, component):\n",
    "    '''\n",
    "    Autoencoder model\n",
    "    \n",
    "    @params:\n",
    "        dfx: DataFrame of normalized x values\n",
    "        y: Predicted value\n",
    "        dims: Number of dimensions\n",
    "        component: Name of gas or particulate\n",
    "    '''\n",
    "\n",
    "    regr = LinearRegression()\n",
    "    variance_list = []\n",
    "    r2_list = []\n",
    "    num_of_comp = list(range(2,dims+1))\n",
    "\n",
    "    for i in num_of_comp:\n",
    "        print('---------- Autoencoder dim {} for {} ----------'.format(i, component))\n",
    "        # Training and test splits\n",
    "        train, dev, train_labels, dev_labels = train_test_split(dfx, y, test_size=0.20, random_state=40)\n",
    "        train, test, train_labels, test_labels = train_test_split(train, train_labels, test_size=0.20, random_state=40)\n",
    "        input_data = Input(shape=(1535,))\n",
    "\n",
    "        x_train = train.loc[:, train.columns]\n",
    "        x_test = test.loc[:, test.columns]\n",
    "        x_dev = dev.loc[:, dev.columns]\n",
    "\n",
    "        encoded = Dense(i, activation='LeakyReLU', name='bottleneck')(input_data)\n",
    "        decoded = Dense(1535, activation='LeakyReLU')(encoded)\n",
    "\n",
    "        autoencoder = Model(input_data, decoded)\n",
    "\n",
    "        # Compile the autoencoder\n",
    "        autoencoder.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
    "        autoencoder.summary()\n",
    "\n",
    "        trained_model = autoencoder.fit(\n",
    "            x_train, \n",
    "            x_train, \n",
    "            batch_size=64, \n",
    "            epochs=150, \n",
    "            verbose=1,\n",
    "            validation_data=(x_dev, x_dev)\n",
    "        )\n",
    "\n",
    "        # Bottleneck representation\n",
    "        encoder = Model(autoencoder.input, autoencoder.get_layer('bottleneck').output)\n",
    "        encoded_data = encoder.predict(x_train)  \n",
    "        decoded_output = autoencoder.predict(x_train)  \n",
    "        decoded_output_test = autoencoder.predict(x_test)\n",
    "\n",
    "        # Variance score explanation\n",
    "        regr.fit(encoded_data, train_labels)\n",
    "\n",
    "        encoded_data_test = encoder.predict(x_test)\n",
    "        y_pred = regr.predict(encoded_data_test) # << Pass x_test to get predicitons for original uncompressed\n",
    "        \n",
    "        # Variance and r2 scores for the regression model\n",
    "        variance = regr.score(encoded_data_test, test_labels) # << pass in x test for uncompressed values\n",
    "        r2_val = r2_score(test_labels, y_pred)\n",
    "        print ('Variance score: %.2f' % variance)\n",
    "        print ('R Square', r2_val)\n",
    "\n",
    "        # Add r2/variance to lists\n",
    "        variance_list.append(variance)\n",
    "        r2_list.append(r2_val)        \n",
    "\n",
    "    return (variance_list, r2_list, encoded_data)\n",
    "\n",
    "\n",
    "def ae_run(dims, component_names):\n",
    "    '''\n",
    "    Run and train the autoencoder model\n",
    "    \n",
    "    @params:\n",
    "        dims: Number of dimensions\n",
    "        component_names: Gas/particulate list\n",
    "    '''\n",
    "\n",
    "    for component in component_names:\n",
    "        print('---------- Beginning Autoencoder training for {} ----------'.format(component))\n",
    "        df = pd.read_csv('C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-testing\\\\Universal-Embeddings-Nick\\\\data\\\\{}_data_clean.csv'.format(component))\n",
    "        \n",
    "        # Features list and removal of city, lat, lon\n",
    "        features = list(df.columns.values)\n",
    "        del features[:3] \n",
    "        del features[-1]\n",
    "\n",
    "        # y value list using last day of 7-month data\n",
    "        y = df.loc[:, ['nh3_2021_06_06'.format(component)]].values\n",
    "\n",
    "        # Normalize x values; save in data frame\n",
    "        x = df.loc[:, features].values\n",
    "        x = Normalizer().fit_transform(x)\n",
    "        dfx = pd.DataFrame(x)\n",
    "\n",
    "        # Train Autoencoder model\n",
    "        variance, r2, X_train = autoencoder(dfx, y, dims, component)\n",
    "\n",
    "        # Normalize var and r2 so they are same length as ax1 and ax2\n",
    "        append_size = len(X_train[:,0]) - dims + 1\n",
    "        norm = np.empty(append_size)\n",
    "        norm[:] = np.NaN\n",
    "        var_norm = [*variance, *norm]\n",
    "        r2_norm = [*r2, *norm]\n",
    "\n",
    "        # Output dict to write \n",
    "        output_dict = {\n",
    "            '{}_X_train_ax1'.format(component): X_train[:,0],\n",
    "            '{}_X_train_ax2'.format(component) : X_train[:,1],\n",
    "            '{}_var'.format(component) : var_norm,\n",
    "            '{}_r2'.format(component) : r2_norm\n",
    "        }\n",
    "\n",
    "        # Write entry to file\n",
    "        file_name = 'C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-testing\\\\Universal-Embeddings-Nick\\\\data\\\\{}_ae_results_grid_para.csv'.format(component)\n",
    "        write_data = pd.DataFrame(data=output_dict)\n",
    "        write_data.to_csv(path_or_buf=file_name, index=False)\n",
    "    \n",
    "### RUN ###\n",
    "\n",
    "\n",
    "COMPONENT_NAMES = ['all']\n",
    "COLORS_LIST = ['tab:blue', 'tab:green', 'tab:orange', 'tab:red', 'tab:purple', 'tab:cyan', 'tab:olive', 'tab:pink']\n",
    "# Starting dimensions; Change this to edit\n",
    "DIMS = 1535\n",
    "\n",
    "# Method tests\n",
    "ae_run(DIMS, COMPONENT_NAMES)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
