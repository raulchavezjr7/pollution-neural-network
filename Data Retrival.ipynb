{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_1\n",
      "start_2\n",
      "start_3\n",
      "start_4\n",
      "start_5\n",
      "start_6\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import config\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from csv import writer\n",
    "\n",
    "\n",
    "def gen_point_data(name, lat, lon, t_start, t_end):\n",
    "    '''\n",
    "    Generate particulate PM2.5 data for a lat/lon point over a set time period and write to csv\n",
    "    @params: \n",
    "        name: name of location\n",
    "        lat, lon: latitude and longitude in decimal degrees\n",
    "        t_start, t_end: starting and ending epoch in Unix time\n",
    "    '''\n",
    "\n",
    "    # Connect to endpoint and load data\n",
    "    endpoint = 'http://api.openweathermap.org/data/2.5/air_pollution/history?lat={LAT}&lon={LON}&start={START}&end={END}&appid={KEY}'.format(\n",
    "        LAT=lat, \n",
    "        LON=lon,\n",
    "        START=t_start,\n",
    "        END=t_end,\n",
    "        KEY=config.OPEN_WEATHER_KEY\n",
    "    )\n",
    "    page = requests.get(url=endpoint)\n",
    "    content = json.loads(page.content)\n",
    "    return content\n",
    "\n",
    "#Setting points for first 1/6 of data\n",
    "print('start_1')\n",
    "\n",
    "#Variable to hold new key fo json key='city'\n",
    "content = {}\n",
    "\n",
    "#retrieve and load city, lat, and lon\n",
    "city_df = pd.read_csv('C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-Nick\\\\Universal-Embeddings-Nick\\\\data\\\\city_lat_lon.csv')\n",
    "city_count = 4723 # Actual: len(city_df)\n",
    "\n",
    "# Start and ending times.\n",
    "T_START = 1606456800\n",
    "T_END = 1623128400\n",
    "\n",
    "#Retrieve city info info to pass to gen_point_data\n",
    "for i in range(city_count): \n",
    "    city_name = city_df.iloc[i][0]\n",
    "    city_lat = city_df.iloc[i][1]\n",
    "    city_lon = city_df.iloc[i][2]\n",
    "    city_info=[city_name, city_lat, city_lon]\n",
    "    # Retrieve particulate list; write row to csv\n",
    "    entry = gen_point_data(name=city_name, lat=city_lat, lon=city_lon, t_start=T_START, t_end=T_END)\n",
    "    content[city_name]=entry\n",
    "    \n",
    "#Create txt file with data\n",
    "with open('raw_data_1_6.txt', 'w') as outfile:\n",
    "    json.dump(content, outfile)\n",
    "\n",
    "# Setting points for first 2/6 of data\n",
    "print('start_2')\n",
    "\n",
    "#Variable to hold new key fo json key='city'\n",
    "content = {}\n",
    "\n",
    "#retrieve and load city, lat, and lon\n",
    "city_df = pd.read_csv('C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-Nick\\\\Universal-Embeddings-Nick\\\\data\\\\city_lat_lon.csv')\n",
    "city_count = 4723*2 # Actual: len(city_df)\n",
    "\n",
    "# Start and ending times. Testing for Dec 2020\n",
    "T_START = 1606456800\n",
    "T_END = 1623128400\n",
    "\n",
    "#Retrieve city info info to pass to gen_point_data\n",
    "#Skip city data already used\n",
    "for i in range(city_count): \n",
    "    if i < 4723 :\n",
    "       pass \n",
    "    else:\n",
    "        city_name = city_df.iloc[i][0]\n",
    "        city_lat = city_df.iloc[i][1]\n",
    "        city_lon = city_df.iloc[i][2]\n",
    "        city_info=[city_name, city_lat, city_lon]\n",
    "        # Retrieve particulate list; write row to csv\n",
    "        entry = gen_point_data(name=city_name, lat=city_lat, lon=city_lon, t_start=T_START, t_end=T_END)\n",
    "        content[city_name]=entry\n",
    "        \n",
    "#Create txt file with data\n",
    "with open('raw_data_2_6.txt', 'w') as outfile:\n",
    "    json.dump(content, outfile)\n",
    "    \n",
    "# Setting points for first 3/6 of data\n",
    "print('start_3')\n",
    "\n",
    "#Variable to hold new key fo json key='city'\n",
    "content = {}\n",
    "\n",
    "#retrieve and load city, lat, and lon\n",
    "city_df = pd.read_csv('C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-Nick\\\\Universal-Embeddings-Nick\\\\data\\\\city_lat_lon.csv')\n",
    "city_count = 4723*3 # Actual: len(city_df)\n",
    "\n",
    "# Start and ending times. Testing for Dec 2020\n",
    "T_START = 1606456800\n",
    "T_END = 1623128400\n",
    "\n",
    "#Retrieve city info info to pass to gen_point_data\n",
    "#Skip city data already used\n",
    "for i in range(city_count): \n",
    "    if i < (4723*2) :\n",
    "       pass \n",
    "    else:\n",
    "        city_name = city_df.iloc[i][0]\n",
    "        city_lat = city_df.iloc[i][1]\n",
    "        city_lon = city_df.iloc[i][2]\n",
    "        city_info=[city_name, city_lat, city_lon]\n",
    "        # Retrieve particulate list; write row to csv\n",
    "        entry = gen_point_data(name=city_name, lat=city_lat, lon=city_lon, t_start=T_START, t_end=T_END)\n",
    "        content[city_name]=entry\n",
    "        \n",
    "#Create txt file with data\n",
    "with open('raw_data_3_6.txt', 'w') as outfile:\n",
    "    json.dump(content, outfile)\n",
    "\n",
    "#Setting points for first 4/6 of data\n",
    "print('start_4')\n",
    "\n",
    "#Variable to hold new key fo json key='city'\n",
    "content = {}\n",
    "\n",
    "#retrieve and load city, lat, and lon\n",
    "city_df = pd.read_csv('C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-Nick\\\\Universal-Embeddings-Nick\\\\data\\\\city_lat_lon.csv')\n",
    "city_count = 4723*4 # Actual: len(city_df)\n",
    "\n",
    "# Start and ending times. Testing for Dec 2020\n",
    "T_START = 1606456800\n",
    "T_END = 1623128400\n",
    "\n",
    "#Retrieve city info info to pass to gen_point_data\n",
    "#Skip city data already used\n",
    "for i in range(city_count): \n",
    "    if i < (4723*3) :\n",
    "       pass \n",
    "    else:\n",
    "        city_name = city_df.iloc[i][0]\n",
    "        city_lat = city_df.iloc[i][1]\n",
    "        city_lon = city_df.iloc[i][2]\n",
    "        city_info=[city_name, city_lat, city_lon]\n",
    "        # Retrieve particulate list; write row to csv\n",
    "        entry = gen_point_data(name=city_name, lat=city_lat, lon=city_lon, t_start=T_START, t_end=T_END)\n",
    "        content[city_name]=entry\n",
    "        \n",
    "#Create txt file with data\n",
    "with open('raw_data_4_6.txt', 'w') as outfile:\n",
    "    json.dump(content, outfile)\n",
    "    \n",
    "# Setting points for first 5/6 of data\n",
    "print('start_5')\n",
    "\n",
    "#Variable to hold new key fo json key='city'\n",
    "content = {}\n",
    "\n",
    "#retrieve and load city, lat, and lon\n",
    "city_df = pd.read_csv('C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-Nick\\\\Universal-Embeddings-Nick\\\\data\\\\city_lat_lon.csv')\n",
    "city_count = 4723*5 # Actual: len(city_df)\n",
    "\n",
    "# Start and ending times. Testing for Dec 2020\n",
    "T_START = 1606456800\n",
    "T_END = 1623128400\n",
    "\n",
    "#Retrieve city info info to pass to gen_point_data\n",
    "#Skip city data already used\n",
    "for i in range(city_count): \n",
    "    if i < (4723*4) :\n",
    "       pass \n",
    "    else:\n",
    "        city_name = city_df.iloc[i][0]\n",
    "        city_lat = city_df.iloc[i][1]\n",
    "        city_lon = city_df.iloc[i][2]\n",
    "        city_info=[city_name, city_lat, city_lon]\n",
    "        # Retrieve particulate list; write row to csv\n",
    "        entry = gen_point_data(name=city_name, lat=city_lat, lon=city_lon, t_start=T_START, t_end=T_END)\n",
    "        content[city_name]=entry\n",
    "        \n",
    "#Create txt file with data\n",
    "with open('raw_data_5_6.txt', 'w') as outfile:\n",
    "    json.dump(content, outfile)\n",
    "    \n",
    "# Setting points for first 6/6 of data\n",
    "print('start_6')\n",
    "\n",
    "#Variable to hold new key fo json key='city'\n",
    "content = {}\n",
    "\n",
    "#retrieve and load city, lat, and lon\n",
    "city_df = pd.read_csv('C:\\\\Users\\\\Kurly\\\\Downloads\\\\Universal-Embeddings-Nick\\\\Universal-Embeddings-Nick\\\\data\\\\city_lat_lon.csv')\n",
    "city_count = 4723*6 # Actual: len(city_df)\n",
    "\n",
    "# Start and ending times. Testing for Dec 2020\n",
    "T_START = 1606456800\n",
    "T_END = 1623128400\n",
    "\n",
    "#Retrieve city info info to pass to gen_point_data\n",
    "#Skip city data already used\n",
    "for i in range(city_count): \n",
    "    if i < (4723*5) :\n",
    "       pass \n",
    "    else:\n",
    "        city_name = city_df.iloc[i][0]\n",
    "        city_lat = city_df.iloc[i][1]\n",
    "        city_lon = city_df.iloc[i][2]\n",
    "        city_info=[city_name, city_lat, city_lon]\n",
    "        # Retrieve particulate list; write row to csv\n",
    "        entry = gen_point_data(name=city_name, lat=city_lat, lon=city_lon, t_start=T_START, t_end=T_END)\n",
    "        content[city_name]=entry\n",
    "        \n",
    "#Create txt file with data\n",
    "with open('raw_data_6_6.txt', 'w') as outfile:\n",
    "    json.dump(content, outfile)\n",
    "\n",
    "print('done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28338"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
